{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baysian classifier for document classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data is about enviroment and international defence news where first 15 article are about defence news and next 15 article are about enviroment and climete change.Then next 10 article are for testing where first 5 article are or defence news and next 5 article are about enviromental news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_table(\"data.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "defence=data.iloc[:15,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment=data.iloc[15:30]\n",
    "environment=environment.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_articles=list(environment[\"News Articals\"])\n",
    "defence_article=list(defence[\"News Articals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "vectorizer1=CountVectorizer()\n",
    "x=vectorizer.fit_transform(defence_article)\n",
    "y=vectorizer1.fit_transform(environment_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=vectorizer.get_feature_names_out()\n",
    "wordlist1=vectorizer1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_probability={}\n",
    "total_word=0\n",
    "for i in range(len(wordlist)):\n",
    "    count=0\n",
    "    for j in range(15):\n",
    "        count+=x.toarray()[j][i]\n",
    "    word_probability[wordlist[i]]=count\n",
    "    total_word+=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_probability1={}\n",
    "total_word1=0\n",
    "for i in range(len(wordlist1)):\n",
    "    count=0\n",
    "    for j in range(15):\n",
    "        count+=y.toarray()[j][i]\n",
    "    word_probability1[wordlist1[i]]=count\n",
    "    total_word1+=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Articals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India and Japan conduct maritime partnership e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creation of standalone air defence command may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rajnath Singh launches 75 AI-powered defence p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO THIRD COUNTRY HAS VETO IN INDIA-U.S. RELATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OUR DEFENCE SHIPYARD PLAYS A PIVOTAL ROLE IN S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is eco-anxiety? The psychological conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In war-torn states hurt by climate, scant hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France's summer heatwaves likely to have cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Countries need to walk the talk on loss and da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is India's action plan to fight emissions...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       News Articals\n",
       "0  India and Japan conduct maritime partnership e...\n",
       "1  Creation of standalone air defence command may...\n",
       "2  Rajnath Singh launches 75 AI-powered defence p...\n",
       "3  NO THIRD COUNTRY HAS VETO IN INDIA-U.S. RELATI...\n",
       "4  OUR DEFENCE SHIPYARD PLAYS A PIVOTAL ROLE IN S...\n",
       "5  What is eco-anxiety? The psychological conditi...\n",
       "6  In war-torn states hurt by climate, scant hope...\n",
       "7  France's summer heatwaves likely to have cause...\n",
       "8  Countries need to walk the talk on loss and da...\n",
       "9  This is India's action plan to fight emissions..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=data.iloc[30:]\n",
    "test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=[\"defence\",\"defence\",\"defence\",\"defence\",\"defence\",\"environment\",\"environment\",\"environment\",\"environment\",\"environment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data,word_probability,word_probability1,wordlist,wordlist1,total_word,total_word1):\n",
    "    y_pred=[]\n",
    "    for i in range(len(test_data)):\n",
    "        defence_prob=1\n",
    "        environment_prob=1\n",
    "        news=test_data.iloc[i,0]\n",
    "        wordarray=news.split(\" \")\n",
    "\n",
    "        for j in wordarray:\n",
    "            if j in [\"and\",\"or\",\"the\",\"a\",\"an\",\"for\",\"by\",\"is\",\"are\",\"must\",\"what\",\"where\"]:\n",
    "                continue\n",
    "            if j in wordlist:\n",
    "                defence_prob*=word_probability[j]\n",
    "            if j in wordlist1:\n",
    "                environment_prob*=word_probability1[j]\n",
    "        if(defence_prob>=environment_prob):\n",
    "            y_pred.append(\"defence\")\n",
    "        else:\n",
    "            y_pred.append(\"environment\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=predict(test_data,word_probability,word_probability1,wordlist,wordlist1,total_word,total_word1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [1, 4]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " The code starts by creating a list of words, wordlist.\n",
    " The code then creates a list of features, vectorizer1.\n",
    " These are the 15 most common words in English (the first line).\n",
    " Then it creates another list of features, vectorizer2.\n",
    " This is the 15 most common words in Spanish (the second line).\n",
    " It then loops through each feature and counts how many times that word appears in both lists combined, x[j][i].\n",
    " Finally it adds up all these numbers to get an overall probability for each word as well as adding them together to get total_word and total_word1.\n",
    " The code starts by creating two lists: one with English words and one with Spanish words.\n",
    " Then it creates a third list called word_probability which will hold the probabilities for every single word from both lists combined into one number so we can compare them later on when we're done looping through all the features.\n",
    " It also creates two variables: total_word which will keep track of how many times each feature has been found across both lists combined; and total_word1 which will do the same thing but only for Spanish phrases instead of just individual English ones because they have different lengths (Spanish has more than\n",
    " The code will iterate through each word in the wordlist, and then iterate through each word in the wordlist1.\n",
    " The number of times that a given word appears in both lists is then added to a list called \"word_probability\" which will be used later on for calculating the probability of a given word appearing.\n",
    " The code above also creates an empty list called \"word_probability1\" which will be used later on for calculating the probability of a given word appearing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f97e529747ebd75ab7a7eec8530cad2ed8018c456aefe1ed5a69bb21bdfd2052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
